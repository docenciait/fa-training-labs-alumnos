## Parte 1: Apache Kafka - La Plataforma de Streaming de Eventos

### ¬øQu√© es Apache Kafka?

Imagina a Kafka no como una simple cola de mensajes, sino como el **sistema nervioso central de datos** de una organizaci√≥n. Es una **plataforma de streaming de eventos distribuida, tolerante a fallos y de alto rendimiento**.

En lugar de simplemente enviar un mensaje de un punto A a un punto B, Kafka est√° dise√±ado para manejar **flujos continuos de eventos** (streams) y almacenarlos de forma duradera. Un "evento" es cualquier cosa que sucede en tu negocio: un clic en una p√°gina web, una venta realizada, una lectura de un sensor de IoT, una transacci√≥n financiera, etc.

Kafka te permite:
1.  **Publicar y Suscribirte (Pub/Sub):** M√∫ltiples aplicaciones (productores) pueden enviar eventos a Kafka, y m√∫ltiples aplicaciones (consumidores) pueden leerlos en tiempo real.
2.  **Almacenar:** Guarda los flujos de eventos de forma segura y duradera por el tiempo que necesites (desde minutos hasta a√±os). Esto es clave: puedes "rebobinar" y volver a procesar eventos pasados.
3.  **Procesar:** Permite el procesamiento de flujos de eventos en tiempo real, ya sea con aplicaciones externas o con la librer√≠a Kafka Streams.

### Conceptos Clave de Kafka

Para entender c√≥mo funciona, necesitas conocer su terminolog√≠a:

* **Evento (o Mensaje):** La unidad de datos en Kafka. Consiste en una clave (opcional), un valor (el dato en s√≠), una marca de tiempo y metadatos.
* **Topic (Tema):** Es una categor√≠a o un "feed" al que se env√≠an los eventos. Piensa en ello como una tabla en una base de datos o una carpeta en un sistema de archivos. En tu c√≥digo, el topic es `"eventos"`.
* **Partici√≥n (Partition):** La clave de la escalabilidad de Kafka. Un topic se divide en una o m√°s particiones. Cada partici√≥n es un **log de eventos ordenado e inmutable**. Los nuevos eventos se a√±aden siempre al final. Kafka garantiza el orden de los mensajes *dentro de una misma partici√≥n*, pero no entre particiones diferentes de un mismo topic.
* **Offset:** Un n√∫mero secuencial √∫nico que identifica a cada evento dentro de una partici√≥n. Los consumidores utilizan este offset para saber qu√© mensajes ya han le√≠do.
* **Broker:** Un servidor de Kafka. Un cl√∫ster de Kafka se compone de varios brokers que trabajan juntos para proporcionar escalabilidad y tolerancia a fallos.
* **Productor (Producer):** Una aplicaci√≥n que escribe (publica) eventos en uno o m√°s topics de Kafka. Tu `producer.py` es un productor.
* **Consumidor (Consumer):** Una aplicaci√≥n que lee (se suscribe) a uno o m√°s topics. Tu `consumer.py` es un consumidor.
* **Grupo de Consumidores (Consumer Group):** Un conjunto de consumidores que trabajan juntos para leer un topic. Kafka distribuye las particiones del topic entre los consumidores del grupo. As√≠, si un topic tiene 4 particiones y tu grupo tiene 4 consumidores, cada uno leer√° de una partici√≥n, logrando un paralelismo perfecto. Si un consumidor se cae, Kafka reasigna su partici√≥n a otro miembro del grupo.

---

## Parte 2: Opciones de Configuraci√≥n Clave

En tu c√≥digo usas varias opciones importantes:

* `bootstrap_servers`: Es la lista de brokers a los que el cliente (productor o consumidor) se conectar√° inicialmente para descubrir el resto del cl√∫ster. No necesita ser la lista completa, solo uno o dos para arrancar.
* `group_id`: Identificador √∫nico para un grupo de consumidores. Es **esencial** para la escalabilidad. Todos los consumidores con el mismo `group_id` pertenecen al mismo grupo y se reparten las particiones de un topic. Si dos consumidores tienen `group_id` diferentes, ambos recibir√°n **todos** los mensajes del topic (comportamiento de broadcast).
* `auto_offset_reset`: Define qu√© hacer cuando un consumidor de un nuevo grupo se conecta por primera vez y no hay un offset guardado para √©l.
    * `"earliest"` (el que usas): El consumidor empezar√° a leer desde el **primer mensaje disponible** en la partici√≥n. Muy √∫til para desarrollo y para procesar datos hist√≥ricos.
    * `"latest"` (el valor por defecto): El consumidor empezar√° a leer solo los **nuevos mensajes** que lleguen despu√©s de que se conecte. Ideal para procesar datos en tiempo real sin importar el pasado.

---

## Parte 3: Kafka vs. RabbitMQ - Una Comparativa

Esta es una pregunta muy com√∫n. Ambos son sistemas de mensajer√≠a excelentes, pero con filosof√≠as y casos de uso diferentes.

| Caracter√≠stica        | Apache Kafka                                                                                                              | RabbitMQ                                                                                                                        |
| :-------------------- | :------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------ |
| **Arquitectura** | **Log de Eventos Distribuido:** Se basa en un log inmutable y replicado. Los mensajes no se eliminan al ser le√≠dos, se retienen seg√∫n una pol√≠tica. | **Broker de Mensajes Tradicional:** Se basa en colas. Los mensajes se eliminan de la cola una vez que son consumidos y confirmados (ACK). |
| **Modelo** | **Pub/Sub a gran escala.** Ideal para difundir datos a m√∫ltiples consumidores o sistemas de forma masiva.                       | **Flexible.** Soporta Pub/Sub, colas de trabajo, enrutamiento complejo (topic, fanout, direct exchanges), RPC, etc. Es un "smart broker". |
| **Rendimiento** | **Rendimiento extremadamente alto** (millones de mensajes/seg). Optimizado para I/O secuencial y batching.                  | **Buen rendimiento** (decenas o cientos de miles de mensajes/seg). M√°s enfocado en la flexibilidad de enrutamiento que en el throughput bruto. |
| **Persistencia** | **Retenci√≥n a largo plazo.** Los datos pueden persistir durante d√≠as, meses o para siempre. Act√∫a como un sistema de almacenamiento. | **Persistencia a corto plazo.** Dise√±ado para actuar como un b√∫fer temporal para los mensajes hasta que son consumidos.                     |
| **Consumidores** | **"Dumb consumers".** La l√≥gica reside en los consumidores, que son responsables de llevar la cuenta de su offset (posici√≥n) en el log. | **"Smart broker".** El broker es responsable de empujar los mensajes a los consumidores y gestionar el estado de la cola.                  |
| **Casos de Uso** | - Streaming de datos a gran escala<br>- An√°lisis en tiempo real<br>- Ingesta de logs y m√©tricas<br>- Sincronizaci√≥n de bases de datos (CDC)<br>- Desacoplamiento de microservicios (event-driven) | - Colas de tareas (task queues)<br>- Enrutamiento de mensajes complejo<br>- Notificaciones a sistemas espec√≠ficos<br>- Desacoplamiento de microservicios (command-driven) |
| **Conclusi√≥n** | **Plataforma de streaming** para pipelines de datos.                                                                       | **Broker de mensajes** para integraci√≥n de aplicaciones.                                                                        |

---

## Parte 4: An√°lisis del C√≥digo

Ahora, vamos a desglosar tu c√≥digo. Est√° muy bien estructurado y sigue buenas pr√°cticas.

### `producer.py` - El que Env√≠a los Eventos

```python
# Importaciones necesarias: FastAPI para la API web, el modelo Pydantic,
# el productor as√≠ncrono de aiokafka, asyncio para tareas as√≠ncronas
# y json para la serializaci√≥n.
from fastapi import FastAPI
from models import Evento
from aiokafka import AIOKafkaProducer
import asyncio
import json
import logging # Aunque importado, no se usa. Ser√≠a bueno para logs m√°s formales.

# Se crea la instancia de la aplicaci√≥n FastAPI.
app = FastAPI()

# Se inicializa la variable global para el productor. Es 'None' al principio.
producer: AIOKafkaProducer = None

# Constantes para la configuraci√≥n. Es una buena pr√°ctica para mantener el c√≥digo limpio.
BOOTSTRAP_SERVERS = "kafka:9092" # "kafka" es el nombre del servicio en Docker Compose.
TOPIC = "eventos"

# Esta funci√≥n es CR√çTICA. Se encarga de crear y conectar el productor a Kafka.
async def get_kafka_producer():
    global producer
    retries = 10 # N√∫mero de intentos de conexi√≥n.
    
    # Bucle de reintentos: muy importante en arquitecturas de microservicios (ej. Docker),
    # donde este servicio puede arrancar ANTES de que el broker de Kafka est√© listo.
    for i in range(retries):
        try:
            # Se instancia el productor, pas√°ndole la direcci√≥n de los brokers.
            producer = AIOKafkaProducer(
                bootstrap_servers=BOOTSTRAP_SERVERS
            )
            # Inicia el productor. Esta es una operaci√≥n de red, por lo que es as√≠ncrona.
            # Establece la conexi√≥n y obtiene metadatos del cl√∫ster.
            await producer.start()
            print("‚úÖ Productor Kafka iniciado correctamente.")
            return # Si tiene √©xito, sale de la funci√≥n.
        except Exception as e:
            # Si la conexi√≥n falla (ej. Kafka no est√° listo), lo imprime y espera.
            print(f"‚ùå Reintentando conexi√≥n a Kafka ({i+1}/{retries}): {e}")
            await asyncio.sleep(3) # Espera 3 segundos antes del siguiente intento.
            
    # Si despu√©s de todos los reintentos no se pudo conectar, lanza un error para detener la aplicaci√≥n.
    raise RuntimeError("üõë No se pudo conectar a Kafka.")

# Decorador de FastAPI que ejecuta esta funci√≥n cuando la aplicaci√≥n arranca.
# Asegura que el productor est√© listo antes de aceptar peticiones.
@app.on_event("startup")
async def startup_event():
    await get_kafka_producer()

# Decorador que se ejecuta cuando la aplicaci√≥n se apaga (ej. con Ctrl+C).
# Es crucial para cerrar las conexiones de forma limpia.
@app.on_event("shutdown")
async def shutdown_event():
    if producer:
        # Detiene el productor, enviando los mensajes pendientes y cerrando conexiones.
        await producer.stop()

# El endpoint de la API que recibe los eventos a trav√©s de una petici√≥n POST.
@app.post("/send")
async def send_message(evento: Evento):
    # Serializa el objeto Pydantic 'Evento' a un diccionario, luego a un string JSON,
    # y finalmente lo codifica a bytes (UTF-8), que es el formato que Kafka espera.
    value = json.dumps(evento.dict()).encode("utf-8")
    
    # Env√≠a el mensaje al topic especificado.
    # 'send_and_wait' es un m√©todo conveniente que espera la confirmaci√≥n (ACK) del broker
    # de que el mensaje ha sido recibido y escrito en la partici√≥n.
    # Esto garantiza la entrega pero puede ser un poco m√°s lento que solo 'send()'.
    await producer.send_and_wait(TOPIC, value=value)
    
    # Devuelve una respuesta confirmando el env√≠o.
    return {"status": "message sent", "evento": evento}
```

### `consumer.py` - El que Lee los Eventos

```python
# Importaciones similares al productor, pero ahora con AIOKafkaConsumer.
from fastapi import FastAPI
from aiokafka import AIOKafkaConsumer
from models import Evento
import json
import asyncio

app = FastAPI()

# Una lista en memoria para guardar los mensajes recibidos.
# En una aplicaci√≥n real, aqu√≠ har√≠as algo m√°s √∫til: guardar en una base de datos,
# procesar los datos, llamar a otra API, etc.
mensajes: list[Evento] = []

# Constantes de configuraci√≥n.
KAFKA_BOOTSTRAP = "kafka:9092"
TOPIC = "eventos"

# Esta es la funci√≥n principal del consumidor. Se ejecutar√° en un bucle infinito.
async def consume():
    # Se instancia el consumidor.
    consumer = AIOKafkaConsumer(
        TOPIC, # El topic (o lista de topics) al que se suscribe.
        bootstrap_servers=KAFKA_BOOTSTRAP,
        # MUY IMPORTANTE: Identifica al consumidor como parte de este grupo.
        # Permite escalar ejecutando varias instancias de este mismo servicio.
        group_id="grupo-consumidor-2", 
        # Como se explic√≥ antes, empieza a leer desde el principio del topic.
        auto_offset_reset="earliest" 
    )
    # Inicia el consumidor y se conecta al cl√∫ster de Kafka.
    await consumer.start()
    try:
        # Este es el bucle de consumo. 'async for' es una forma elegante y eficiente
        # de esperar y procesar mensajes a medida que llegan, sin bloquear el hilo.
        async for msg in consumer:
            # 'msg.value' contiene el mensaje en bytes. Se decodifica a string.
            data = json.loads(msg.value.decode())
            # Se convierte el diccionario JSON de vuelta a un objeto Pydantic 'Evento'.
            # Esto valida que el mensaje tiene la estructura esperada.
            evento = Evento(**data)
            
            # Imprime el evento recibido.
            print(f"üì• Recibido evento: {evento.tipo} con ID {evento.id}")
            
            # A√±ade el evento a la lista en memoria.
            mensajes.append(evento)
    finally:
        # Este bloque se asegura de que, si el bucle termina por cualquier raz√≥n
        # (aunque en este caso no deber√≠a), el consumidor se detenga limpiamente.
        await consumer.stop()

# En el evento de arranque de la aplicaci√≥n FastAPI...
@app.on_event("startup")
async def startup_event():
    # ...se crea una tarea en segundo plano para ejecutar la funci√≥n 'consume'.
    # asyncio.create_task() es VITAL aqu√≠. Lanza el bucle de consumo para que se ejecute
    # concurrentemente, sin bloquear el arranque del servidor web de FastAPI.
    # As√≠, la API puede servir peticiones (como /messages) mientras consume de Kafka.
    asyncio.create_task(consume())

# Un endpoint de prueba para ver los mensajes que se han consumido.
@app.get("/messages")
async def get_messages():
    # Devuelve el contenido de la lista 'mensajes'.
    return [m.dict() for m in mensajes]
